{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    # Print image's original shape, for reference\n",
    "    print('Original image shape: ', mpimg.imread(image_path).shape)\n",
    "    \n",
    "    # Load in the image with a target size of 200,200\n",
    "    image = image_utils.load_img(image_path, target_size=(200, 200))\n",
    "    # Convert the image from a PIL format to a numpy array\n",
    "    image = image_utils.img_to_array(image)\n",
    "    # Add a dimension for number of images, in our case 1\n",
    "    image = image.reshape(1,200,200,3)\n",
    "    # Preprocess image to align with original ImageNet dataset\n",
    "    image = preprocess_input(image)\n",
    "    # Print image's shape after processing\n",
    "    print('Processed image shape: ', image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行预测\n",
    "from tensorflow.keras.applications.vgg19 import decode_predictions\n",
    "\n",
    "def readable_prediction(image_path):\n",
    "    # Show image\n",
    "    show_image(image_path)\n",
    "    # Load and pre-process image\n",
    "    image = load_and_process_image(image_path)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(image)\n",
    "    # Print predictions in readable form\n",
    "    print('Predicted:', decode_predictions(predictions, top=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(200, 200, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inputs = keras.Input(shape=(200,200,3))\n",
    "# Separately from setting trainable on the model, we set training to ase \n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(4,activation='softmax')(x) \n",
    "################注意!此处只有一个分类\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Functional)           (None, 6, 6, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 20,026,436\n",
      "Trainable params: 2,052\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to use binary crossentropy and binary accuracy as we now have a binary classification problem\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以先简化问题\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # load and iterate training dataset\\n    train_it = datagen.flow_from_directory(\"C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_train\", \\n                                        target_size=(200, 200), \\n                                        color_mode=\\'rgb\\', \\n                                        batch_size=8)\\n    # load and iterate validation dataset\\n    valid_it = datagen.flow_from_directory(\\'C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_valid\\', \\n                                        target_size=(200, 200), \\n                                        color_mode=\\'rgb\\',  \\n                                        batch_size=8)\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    # load and iterate training dataset\n",
    "    train_it = datagen.flow_from_directory(\"C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                        target_size=(200, 200), \n",
    "                                        color_mode='rgb', \n",
    "                                        batch_size=8)\n",
    "    # load and iterate validation dataset\n",
    "    valid_it = datagen.flow_from_directory('C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_valid', \n",
    "                                        target_size=(200, 200), \n",
    "                                        color_mode='rgb',  \n",
    "                                        batch_size=8)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # load and iterate training dataset\\n    train_it = datagen.flow_from_directory( \"C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_train\", \\n                                        target_size=(200, 200), \\n                                        color_mode=\\'rgb\\', \\n                                        batch_size=8,\\n                                        validation_split=0.)\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    # load and iterate training dataset\n",
    "    train_it = datagen.flow_from_directory( \"C:/Users/Admin/Desktop/ASL数据集2-kaggle/asl_alphabet_train/asl_alphabet_train\", \n",
    "                                        target_size=(200, 200), \n",
    "                                        color_mode='rgb', \n",
    "                                        batch_size=8,\n",
    "                                        validation_split=0.)\n",
    "'''                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11897 files belonging to 4 classes.\n",
      "Using 2379 files for validation.\n",
      "Found 11897 files belonging to 4 classes.\n",
      "Using 9518 files for training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "train_it = tf.keras.preprocessing.image_dataset_from_directory('训练集',\n",
    "image_size=(200,200),subset='validation',validation_split=0.2,seed = 123,label_mode='categorical',shuffle=True )\n",
    "valid_it = tf.keras.preprocessing.image_dataset_from_directory('训练集',\n",
    "image_size=(200,200),subset='training',validation_split=0.2,seed = 123,label_mode='categorical',shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10164/3618876245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_it\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 48/120 [===========>..................] - ETA: 5:19 - loss: 0.6025 - accuracy: 0.7949WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1200.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "120/120 [==============================] - 232s 2s/step - loss: 0.6025 - accuracy: 0.7949 - val_loss: 0.1264 - val_accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc93603c8d0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = 9000#输入数据的长度\n",
    "batch_size1=75\n",
    "model.fit(train_it,validation_data=valid_it, validation_steps=4, epochs=10,batch_size=batch_size1,steps_per_epoch=len_data/batch_size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training_modle/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('training_modle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型微调\n",
    "base_model.trainable = True\n",
    "\n",
    "# It's important to recompile your model after you make any changes\n",
    "# to the `trainable` attribute of any inner layer, so that your changes\n",
    "# are taken into account\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 2/12 [====>.........................] - ETA: 3:01 - loss: 5.3644e-07 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查预测结果\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def make_predictions(image_path):\n",
    "    show_image(image_path)\n",
    "    image = image_utils.load_img(image_path, target_size=(200, 200))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,200,200,3)\n",
    "    image = preprocess_input(image)\n",
    "    preds = model.predict(image)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: training_model_1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('training_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # python中的opencv-python库，著名的计算机视觉库\n",
    "import numpy as np\n",
    "#采集视频、显示并保存        \n",
    "dictionary = {0:' 未知 ',1:'a',2:'b',3:'c',4:'d'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('training_modle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def capturevideoSave(imgName,camera = 0):\n",
    "    # camera 表示摄像头，内置摄像头:0, 外接摄像为按照顺序依次为1,2,3...\n",
    "    cap=cv2.VideoCapture(camera)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    global_num = 0 \n",
    "    while(1):\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        \n",
    "        #图片压缩到合适大小\n",
    "        frame = cv2.resize(frame,(200,200))\n",
    "        #######更改图片亮度\n",
    "        \n",
    "        #镜像处理显示\n",
    "        frame_show =np.fliplr(frame)\n",
    "        cv2.imshow(\"capture\", frame_show)\n",
    "        frame = frame.reshape(1,200,200,3) \n",
    "        frame = frame/255\n",
    "        prediction = model(frame)\n",
    "        a = np.max(prediction)\n",
    "        if a >= 0.4:\n",
    "            predicted_letter = dictionary[np.argmax(prediction)]\n",
    "            print(predicted_letter)\n",
    "            print(a)\n",
    "        else:\n",
    "            print('未识别到目标，请重新识别')\n",
    "            print(a)\n",
    "        #更改窗口大小\n",
    "        #cv2.resizeWindow(\"capture\", 640, 480)\n",
    "        k=cv2.waitKey(1) #等待1ms，获取用户的键盘输入\n",
    "        \n",
    "        \n",
    "        if k==ord(' '): #如果用户输入空格，将当前帧用imgName作为文件名保存\n",
    "            cv2.imwrite(imgName+'.jpg',frame)\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgName  #返回保存的文件名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "0.49025992\n",
      "b\n",
      "0.49329993\n",
      "b\n",
      "0.4865405\n",
      "b\n",
      "0.47250766\n",
      "b\n",
      "0.45286736\n",
      "b\n",
      "0.4456797\n",
      "b\n",
      "0.46837822\n",
      "b\n",
      "0.46866685\n",
      "b\n",
      "0.4691648\n",
      "b\n",
      "0.46608934\n",
      "b\n",
      "0.45912832\n",
      "b\n",
      "0.4774534\n",
      "b\n",
      "0.4744197\n",
      "b\n",
      "0.46743566\n",
      "b\n",
      "0.47051296\n",
      "b\n",
      "0.48141268\n",
      "b\n",
      "0.4761827\n",
      "b\n",
      "0.47586322\n",
      "b\n",
      "0.4780271\n",
      "b\n",
      "0.49656272\n",
      "b\n",
      "0.4826325\n",
      "b\n",
      "0.4923485\n",
      "b\n",
      "0.4765888\n",
      "b\n",
      "0.48576018\n",
      "b\n",
      "0.46408862\n",
      "b\n",
      "0.47790885\n",
      "b\n",
      "0.4964571\n",
      "b\n",
      "0.49084035\n",
      "b\n",
      "0.46782857\n",
      "b\n",
      "0.46557084\n",
      "b\n",
      "0.46221688\n",
      "b\n",
      "0.49372047\n",
      "b\n",
      "0.49961215\n",
      "b\n",
      "0.51253796\n",
      "b\n",
      "0.5157582\n",
      "b\n",
      "0.48908234\n",
      "b\n",
      "0.489393\n",
      "b\n",
      "0.4866784\n",
      "b\n",
      "0.49573842\n",
      "b\n",
      "0.48982617\n",
      "b\n",
      "0.48418552\n",
      "b\n",
      "0.4867565\n",
      "b\n",
      "0.49644843\n",
      "b\n",
      "0.5056465\n",
      "b\n",
      "0.5028487\n",
      "b\n",
      "0.49958283\n",
      "b\n",
      "0.49859366\n",
      "b\n",
      "0.4985057\n",
      "b\n",
      "0.4806466\n",
      "b\n",
      "0.47961038\n",
      "b\n",
      "0.49119452\n",
      "b\n",
      "0.47807613\n",
      "b\n",
      "0.4902393\n",
      "b\n",
      "0.4935956\n",
      "b\n",
      "0.49577117\n",
      "b\n",
      "0.50434417\n",
      "b\n",
      "0.49952915\n",
      "b\n",
      "0.50363487\n",
      "b\n",
      "0.49845424\n",
      "b\n",
      "0.4885156\n",
      "b\n",
      "0.48814023\n",
      "b\n",
      "0.48744366\n",
      "b\n",
      "0.4944274\n",
      "b\n",
      "0.49261957\n",
      "b\n",
      "0.48288006\n",
      "b\n",
      "0.47001874\n",
      "b\n",
      "0.4712406\n",
      "b\n",
      "0.4645219\n",
      "b\n",
      "0.44457772\n",
      "b\n",
      "0.44143966\n",
      "b\n",
      "0.4487027\n",
      "b\n",
      "0.4480397\n",
      "b\n",
      "0.45042533\n",
      "b\n",
      "0.45667896\n",
      "b\n",
      "0.47488102\n",
      "b\n",
      "0.50934297\n",
      "b\n",
      "0.4900237\n",
      "b\n",
      "0.5021405\n",
      "b\n",
      "0.48541006\n",
      "b\n",
      "0.48606077\n",
      "b\n",
      "0.480832\n",
      "b\n",
      "0.4840337\n",
      "b\n",
      "0.46767658\n",
      "b\n",
      "0.46457285\n",
      "b\n",
      "0.46578842\n",
      "b\n",
      "0.4623518\n",
      "b\n",
      "0.46810508\n",
      "b\n",
      "0.46537593\n",
      "b\n",
      "0.47306114\n",
      "b\n",
      "0.50592613\n",
      "b\n",
      "0.49877605\n",
      "b\n",
      "0.4896437\n",
      "b\n",
      "0.48065123\n",
      "b\n",
      "0.48183537\n",
      "b\n",
      "0.49258602\n",
      "b\n",
      "0.49272183\n",
      "b\n",
      "0.49605164\n",
      "b\n",
      "0.48152465\n",
      "b\n",
      "0.42139417\n",
      "b\n",
      "0.44721773\n",
      "b\n",
      "0.45375326\n",
      "b\n",
      "0.43327183\n",
      "b\n",
      "0.42592183\n",
      "b\n",
      "0.42951775\n",
      "b\n",
      "0.42144203\n",
      "b\n",
      "0.43132997\n",
      "b\n",
      "0.43876916\n",
      "b\n",
      "0.4542732\n",
      "b\n",
      "0.4582505\n",
      "b\n",
      "0.4745288\n",
      "b\n",
      "0.46990386\n",
      "b\n",
      "0.47018924\n",
      "b\n",
      "0.4702743\n",
      "b\n",
      "0.46408817\n",
      "b\n",
      "0.4666334\n",
      "b\n",
      "0.46264604\n",
      "b\n",
      "0.48857585\n",
      "b\n",
      "0.4749519\n",
      "b\n",
      "0.47126862\n",
      "b\n",
      "0.4648379\n",
      "b\n",
      "0.4582441\n",
      "b\n",
      "0.5047961\n",
      "b\n",
      "0.5321043\n",
      "b\n",
      "0.51620364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capturevideoSave('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#手势识别对比\n",
    "\n",
    "def capturevideoSave(imgName,camera = 0):\n",
    "    # camera 表示摄像头，内置摄像头:0, 外接摄像为按照顺序依次为1,2,3...\n",
    "    cap=cv2.VideoCapture(camera)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    global_num = 0 \n",
    "    while(1):\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        \n",
    "        #图片压缩到合适大小\n",
    "        frame = cv2.resize(frame,(200,200))\n",
    "        #######更改图片亮度\n",
    "        \n",
    "        #镜像处理显示\n",
    "        frame_show =np.fliplr(frame)\n",
    "        cv2.imshow(\"capture\", frame_show)\n",
    "        frame = frame.reshape(1,200,200,3) \n",
    "        frame = frame/255\n",
    "        prediction = model(frame)\n",
    "        a = np.max(prediction)\n",
    "        if a >= 0.6:\n",
    "            predicted_letter = dictionary[np.argmax(prediction)]\n",
    "            print(predicted_letter)\n",
    "            print(a)\n",
    "        else:\n",
    "            print('未识别到目标，请重新识别')\n",
    "            print(a)\n",
    "        #更改窗口大小\n",
    "        #cv2.resizeWindow(\"capture\", 640, 480)\n",
    "        k=cv2.waitKey(1) #等待1ms，获取用户的键盘输入\n",
    "        \n",
    "        \n",
    "        if k==ord(' '): #如果用户输入空格，将当前帧用imgName作为文件名保存\n",
    "            cv2.imwrite(imgName,frame)\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return imgName  #返回保存的文件名\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
